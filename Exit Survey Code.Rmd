---
title: "Exit Survey"
author: "Artemas Wang"
date: "10/12/2020"
output: html_document
---
```{r } 
```

```{r - loading in required packages}
library(tidyverse)
library(data.table)
library(tm) 
library(tidytext)
library(wordcloud2)
```

```{r - loading in data}
original_data <- fread(paste0("Exit_Survey_8-15-2019.csv"), header = T, stringsAsFactors = F, data.table = T)
exit_data <- original_data
```

```{r - exploring data}
head(exit_data)
colnames(exit_data) 
str(exit_data)

#insert date cut off 8-15-2019
# Removing duplicate column names
which(duplicated(colnames(exit_data))) 
exit_data$Q39_title <- exit_data[, 49]
exit_data$Q23_schoolyear <- exit_data[, 105]
exit_data$Q16_primary_grade <- exit_data[, 107] 
exit_data[, 49] <- NULL
exit_data[, 104] <- NULL
exit_data[, 105] <- NULL

# Changing open-ended responses row names so it makes sense
colnames(exit_data)[colnames(exit_data) %in% c("Q55", "Q56", "Q140")] <- c("Expectations/Reality", "Things Done Differently", "Three things to do")
```

```{r - cleaning the data} 
# Removing Unnecessary Variables
exit_data <- exit_data %>%
  select(., -StartDate, -Status, -IPAddress, -Finished, -LocationLatitude, -LocationLongitude, -Progress, -`Duration (in seconds)`, -RecipientEmail, -RecipientFirstName, -RecipientLastName,
         -DistributionChannel, -ExternalReference, -UserLanguage) # End date excluded
```

```{r - creating questions list to add later}
# Taking the first row (which contains the question text)
exit_data_questions <- as.data.frame(t(exit_data[1,]))

# Adding the codes currently in the dataset
exit_data_questions$Code <- row.names(exit_data_questions)

# Setting the values as the question text (to clean up the question text and remove the difficult references)
exit_data_questions$Value <- str_replace_all(exit_data_questions$`V1`, "\\n", " ")

# Removing the old reference
exit_data_questions$`V1` <- NULL

# Placing Questions into Categories
exit_data_questions$Type <- 
  ifelse(exit_data_questions$Code %in% c("Q2", "Q1", "Q3"), "Intro Questions",
  ifelse(exit_data_questions$Code %in% c("Q8", "Q12", "Q10", "Q18", "Q14","Q20","Q22", 
                                         "Q23_schoolyear", "Q16_primary_grade"), "Demographic Questions", 
  ifelse(exit_data_questions$Code %in% c("Q138", "Q55", "Q56", "Q140", "Q139", "Q42", "Q47", "Q65", "Q44", 
                                         "Q43","Q45", "Q141", "Q16", "Q17", "Q62", "Q126", 
                                        "Q49", "Q125"),"Questions for Everybody", 
  ifelse(exit_data_questions$Code %in% c("Q39_title"), "Questions for Everybody", 
  ifelse(exit_data_questions$Code %in% c("Expectations/Reality","Things Done Differently", 
                                        "Three things to do"), 
                                        "Questions for Everybody - Open-Ended", "Reasons for Departure")))))
```

```{r - Pivoting from wide to long} 
# Renaming demographic questions
exit_data <- exit_data %>% rename(Gender = Q12,
                                            Race.Ethnicity = Q10,
                                            LGBTQ = Q14,
                                            First.Generation.College = Q18)

# Pivoting all questions from wide to long
exit_data_long <- exit_data %>% gather(key = Question, value = Response, -ResponseId, -RecordedDate)

# Filtering out questions with no responses (could omit this step)
exit_data_long <- exit_data_long %>% filter(Response != "")
```

```{r - Preparing final data}
# Adding in questions
exit_data_final <- merge(x = exit_data_long, y = exit_data_questions, by.x = "Question", by.y = "Code", all.x = TRUE)

# Making sure everything is good
str(exit_data_final)
table(exit_data_final$Value, useNA = "always")

# Making question text the question variable in the dataset
exit_data_final <- exit_data_final %>% rename(Question_Code = Question)
exit_data_final <- exit_data_final %>% rename(Question = Value)

# Writing final data to csv
write.csv(exit_data_final, "Exit_Survey_Data_8_15_2019_For_Use.csv", row.names=FALSE)

#write.csv(exit_data_final, "Exit_Survey_Data_Qualtrics_CLEANED.csv", row.names=FALSE)
```

```{r - checking some variables} 
```

# Sentiment Analysis
```{r - creating the stop words}
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
data("stop_words")
word <- c("in","a","of","the","like","classroom","feel","didnt","day","ive") 
stop_words <- c(stop_words$word, word) 

```

```{r - finding most words}
null_value_removal <- Corpus(VectorSource(exit_data$`Expectations/Reality`)) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeWords, character(0)) %>%
  tm_map(removeWords, stop_words) %>%
  tm_map(removeNumbers) %>%
  tm_map(stripWhitespace) %>%
  tm_map(leadingWhitespace)

word_matrix <- TermDocumentMatrix(null_value_removal)
most_words <- word_matrix %>% tidy() %>% filter(count > 1)
most_words_count <- summarise(group_by(most_words, term), sum(count))

most_words_count

set.seed(112)
wordcloud2(most_words_count, 
           size = 3,
           color = 'random-light',
           backgroundColor = 'dark grey', minSize = 5)
```

```{r - sentiment analysis}

sentiment_positive <- get_sentiments("bing") %>% filter(sentiment == "positive")
sentiment_negative <- get_sentiments("bing") %>% filter(sentiment == "negative")

positive_score <- get_sentiments("afinn") %>% filter(value == "3")
negative_score <- get_sentiments("afinn") %>% filter(value == "-3")

zz <- most_words_count %>% anti_join(stop_words, by=c("text"="word"))
zzz <- most_words_count %>% inner_join(get_sentiments("bing")) %>% 
                  count(word, sentiment, sort = TRUE) %>%
                  ungroup()
```










